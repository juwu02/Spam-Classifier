{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_spam_classifier.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "L5uOcqlytPRB",
        "upV0uVEJr3qP",
        "IZAmFF45sID3",
        "JcvvcdW6sMNm",
        "li8JtT5lsQov",
        "yLTc00h5sUQB",
        "UHZAAiwd7HCf",
        "QmLnY-sTsYWY",
        "B2qUUS-YIHtD",
        "ixyZp1rMsjxP"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Eaoow8Kr5oP"
      },
      "source": [
        "# Chapter 1: Build a spam classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5uOcqlytPRB"
      },
      "source": [
        "# 1. Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjZsPeOOcyDc"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('max_colwidth', 5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "id": "l-cIIMLwDFem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_tabular import LimeTabularExplainer"
      ],
      "metadata": {
        "id": "2PfT8Km4DJ6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upV0uVEJr3qP"
      },
      "source": [
        "# 2. Load and inspect the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BafgGzINc_Fy"
      },
      "source": [
        "# load the CSV data to a Pandas dataframe\n",
        "df = pd.read_csv('spam_ham_dataset.csv')\n",
        "# show the first two rows of the dataframe\n",
        "display(df.head(2))\n",
        "# show detailed information about column names, data types and missing values\n",
        "print(df.info())\n",
        "# 'Loan_Status' is the label: show a bar-chart of the class frequencies\n",
        "df['label'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSyXaerBsA2V"
      },
      "source": [
        "## 2.1 Show examples of spam and ham emails"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgRP4gNxda96"
      },
      "source": [
        "df.query('label==\"spam\"')['text'].replace('\\s+', ' ', regex=True).iloc[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzDq5mPrj6_e"
      },
      "source": [
        "df.query('label==\"ham\"')['text'].replace('\\s+', ' ', regex=True).iloc[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZAmFF45sID3"
      },
      "source": [
        "# 3. Build the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcvvcdW6sMNm"
      },
      "source": [
        "## 3.1 Training/Test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qef9QpO1ghLS"
      },
      "source": [
        "# 80%/20% stratified split (use class label for stratification)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(df[['email_id', 'text']],\n",
        "                                                    df['label'],\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42,\n",
        "                                                    stratify=df['label'])\n",
        "\n",
        "print('Size of Training Data ', X_train.shape[0])\n",
        "print('Size of Test Data ', X_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li8JtT5lsQov"
      },
      "source": [
        "## 3.2 Generate features\n",
        "Converts text content into features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M_JL2LYhY6g"
      },
      "source": [
        "tfidf = TfidfVectorizer(min_df = 10, ngram_range=(1,2), stop_words=\"english\")\n",
        "X_train_tf = tfidf.fit_transform(X_train['text'])\n",
        "X_test_tf = tfidf.transform(X_test['text'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLTc00h5sUQB"
      },
      "source": [
        "## 3.3 Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vgcn2Q5Bhd9r"
      },
      "source": [
        "# define model type and hyper-parameter values\n",
        "model = MultinomialNB()\n",
        "\n",
        "# fit the model to the training data\n",
        "model.fit(X_train_tf, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHZAAiwd7HCf"
      },
      "source": [
        "## 3.4 Train a baseline\n",
        "Use \"uniform\" (random classification) as strategy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sTVj4DT7F30"
      },
      "source": [
        "baseline = DummyClassifier(strategy=\"uniform\")\n",
        "baseline.fit(X_train_tf, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmLnY-sTsYWY"
      },
      "source": [
        "## 3.5 Generate predictions for the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBfZDnuMh1gg"
      },
      "source": [
        "Y_pred = model.predict(X_test_tf)\n",
        "Y_pred_baseline = baseline.predict(X_test_tf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXZBAdjxscUB"
      },
      "source": [
        "# 4. Evaluate the predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Evaluation with Confusion Matrix"
      ],
      "metadata": {
        "id": "B2qUUS-YIHtD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MopUpFV4iE0M"
      },
      "source": [
        "def plot_confusion_matrix(confusion_matrix, class_labels):\n",
        "  ax= plt.subplot()\n",
        "\n",
        "  sns.heatmap(confusion_matrix, annot=True, fmt='', cmap='Blues')\n",
        "  ax.set_xlabel('Predicted')\n",
        "  ax.set_ylabel('Actual');\n",
        "  ax.xaxis.set_ticklabels(class_labels)\n",
        "  ax.yaxis.set_ticklabels(class_labels);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pH5iSdRm7zTC"
      },
      "source": [
        "cf_matrix = confusion_matrix(Y_test, Y_pred)\n",
        "plot_confusion_matrix(cf_matrix, list(model.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNrh8UbM73DJ"
      },
      "source": [
        "cf_matrix_baseline = confusion_matrix(Y_test, Y_pred_baseline)\n",
        "plot_confusion_matrix(cf_matrix_baseline, list(baseline.classes_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixyZp1rMsjxP"
      },
      "source": [
        "# 5. Understanding the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GD_tVzaim3k"
      },
      "source": [
        "explainer = LimeTabularExplainer(X_train_tf,\n",
        "                                 mode='classification',\n",
        "                                 class_names=list(model.classes_),\n",
        "                                 feature_names=tfidf.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qEgNp3Bi7sL"
      },
      "source": [
        "X_test[(Y_test == 'spam')].iloc[100]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSAjerL4ipWw"
      },
      "source": [
        "explanation = explainer.explain_instance(X_test_tf[np.array(Y_test == 'spam')][100,:],\n",
        "                                         model.predict_proba,\n",
        "                                         num_features=10)\n",
        "explanation.show_in_notebook()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}